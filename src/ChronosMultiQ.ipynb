{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "gpu"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Chronos_Fx-Price Finetuned Multi Q\n"
      ],
      "metadata": {
        "id": "uWevYQyV_WWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install chronos-forecasting"
      ],
      "metadata": {
        "id": "0jlxEGfl_WWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from chronos import BaseChronosPipeline\n",
        "\n",
        "pipeline = BaseChronosPipeline.from_pretrained(\"amazon/chronos-2\", device_map=\"cuda\")\n"
      ],
      "metadata": {
        "id": "DFZHJLH__WWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Chronos-2 – Multi-FX walk-forward (quarterly, levels) with fine-tuning\n",
        "and unified metrics.\n",
        "\n",
        "- Data: MultiFXData.csv (comma CSV, dot decimals) at:\n",
        "  https://raw.githubusercontent.com/bredeespelid/Data_MasterOppgave/refs/heads/main/EURNOK/MultiFXData.csv\n",
        "- Fine-tuning panel: Norges Bank FX panel 1980–1999 at:\n",
        "  https://raw.githubusercontent.com/bredeespelid/Data_MasterOppgave/refs/heads/main/FineTuneData/NB1980-1999.csv\n",
        "\n",
        "- Fine-tune: Chronos-2 on 1980–1999 FX panel (price-only, multiple series)\n",
        "- Cut (evaluation): last business day in previous quarter\n",
        "- Forecast next quarter at daily frequency -> aggregate to quarterly mean over business days\n",
        "- Evaluation starts strictly after the fine-tuning period (first quarter after ft_end)\n",
        "- Per FX: Observations, RMSE, MAE, Directional Accuracy, DM test vs Random Walk (MSE, h=1)\n",
        "- Outputs: metrics CSV (one row per series)\n",
        "\n",
        "Prereqs:\n",
        "  pip install pandas numpy scikit-learn requests certifi\n",
        "  pip install torch\n",
        "  pip install chronos-forecasting>=2.0\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "import io, time, math\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, Tuple, Dict, Callable, List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests, certifi\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "import torch\n",
        "from chronos import BaseChronosPipeline  # chronos-forecasting>=2.0\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Config\n",
        "# -----------------------------\n",
        "@dataclass\n",
        "class Config:\n",
        "    # Evaluation data (multi-FX)\n",
        "    url_multi: str = (\n",
        "        \"https://raw.githubusercontent.com/bredeespelid/\"\n",
        "        \"Data_MasterOppgave/refs/heads/main/EURNOK/MultiFXData.csv\"\n",
        "    )\n",
        "    # Fine-tuning panel\n",
        "    url_finetune: str = (\n",
        "        \"https://raw.githubusercontent.com/bredeespelid/\"\n",
        "        \"Data_MasterOppgave/refs/heads/main/FineTuneData/NB1980-1999.csv\"\n",
        "    )\n",
        "\n",
        "    q_freq: str = \"Q-DEC\"        # quarterly periods (year ending in December)\n",
        "    min_hist_days: int = 40\n",
        "    max_context: int = 2048\n",
        "    max_horizon: int = 256\n",
        "    retries: int = 3\n",
        "    timeout: int = 60\n",
        "    verbose: bool = True\n",
        "    metrics_csv: str = \"FX_Chronos2_finetuned_metrics_quarterly.csv\"\n",
        "    include_fx: Optional[List[str]] = None  # e.g. [\"EUR\", \"USD\", \"SEK\", \"DKK\", \"GBP\"]\n",
        "\n",
        "    # Fine-tuning hyperparameters\n",
        "    ft_prediction_length: int = 32\n",
        "    ft_num_steps: int = 50\n",
        "    ft_learning_rate: float = 1e-5\n",
        "    ft_batch_size: int = 2\n",
        "    ft_logging_steps: int = 10\n",
        "\n",
        "\n",
        "CFG = Config()\n",
        "\n",
        "# FX columns used for fine-tuning\n",
        "FINETUNE_FX_COLS = [\n",
        "    \"AUD\", \"CAD\", \"CHF\", \"DKK\", \"GBP\",\n",
        "    \"ISK\", \"JPY\", \"NZD\", \"SEK\", \"USD\", \"XDR\",\n",
        "]\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Download & data prep\n",
        "# -----------------------------\n",
        "def download_csv_text(url: str, retries: int, timeout: int) -> str:\n",
        "    \"\"\"Download CSV text with simple retry/backoff.\"\"\"\n",
        "    last_err = None\n",
        "    for k in range(1, retries + 1):\n",
        "        try:\n",
        "            r = requests.get(url, timeout=timeout, verify=certifi.where())\n",
        "            r.raise_for_status()\n",
        "            return r.text\n",
        "        except Exception as e:\n",
        "            last_err = e\n",
        "            if k < retries:\n",
        "                wait = 1.5 * k\n",
        "                print(f\"[warning] Download failed (try {k}/{retries}): {e}. Retrying in {wait:.1f}s ...\")\n",
        "                time.sleep(wait)\n",
        "    raise RuntimeError(f\"Download failed: {last_err}\")\n",
        "\n",
        "\n",
        "def load_multi_fx(url: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Reads MultiFXData.csv with columns like:\n",
        "      DATE, I44, AUD, CHF, DKK, EUR, CAD, GBP, ..., USD, ...\n",
        "\n",
        "    Robust to:\n",
        "      - comma vs semicolon separator\n",
        "      - dot vs comma decimals\n",
        "\n",
        "    Returns daily DataFrame indexed by DATE with ffilled numeric series.\n",
        "    \"\"\"\n",
        "    text = download_csv_text(url, CFG.retries, CFG.timeout)\n",
        "\n",
        "    def _try_read(sep: str, decimal: str) -> pd.DataFrame:\n",
        "        return pd.read_csv(io.StringIO(text), sep=sep, encoding=\"utf-8-sig\", decimal=decimal)\n",
        "\n",
        "    # 1) Try comma + dot (standard CSV)\n",
        "    raw = _try_read(\",\", \".\")\n",
        "    if \"DATE\" not in raw.columns:\n",
        "        # 2) Try semicolon + dot\n",
        "        raw = _try_read(\";\", \".\")\n",
        "    if \"DATE\" not in raw.columns:\n",
        "        # 3) Try comma + comma-decimal, then semicolon + comma-decimal\n",
        "        for sep in (\",\", \";\"):\n",
        "            raw = _try_read(sep, \",\")\n",
        "            if \"DATE\" in raw.columns:\n",
        "                break\n",
        "\n",
        "    if \"DATE\" not in raw.columns:\n",
        "        raise ValueError(f\"Expected a DATE column; got: {list(raw.columns)[:10]} ...\")\n",
        "\n",
        "    raw[\"DATE\"] = pd.to_datetime(raw[\"DATE\"], errors=\"coerce\")\n",
        "    raw = raw.dropna(subset=[\"DATE\"]).sort_values(\"DATE\").set_index(\"DATE\")\n",
        "\n",
        "    num_df = raw.apply(pd.to_numeric, errors=\"coerce\")\n",
        "    daily_idx = pd.date_range(num_df.index.min(), num_df.index.max(), freq=\"D\")\n",
        "    df_d = num_df.reindex(daily_idx).ffill()\n",
        "    df_d.index.name = \"DATE\"\n",
        "    return df_d\n",
        "\n",
        "\n",
        "\n",
        "def series_daily_and_b(df_d: pd.DataFrame, col: str) -> Tuple[pd.Series, pd.Series]:\n",
        "    \"\"\"\n",
        "    For one FX column -> returns (S_b, S_d).\n",
        "\n",
        "    S_d: daily calendar series\n",
        "    S_b: business-day series (B, forward-filled)\n",
        "    \"\"\"\n",
        "    if col not in df_d.columns:\n",
        "        raise ValueError(f\"Column {col} not found.\")\n",
        "    S_d = df_d[col].astype(float)\n",
        "    S_d.name = col\n",
        "    S_b = S_d.asfreq(\"B\").ffill()\n",
        "    S_b.name = col\n",
        "    return S_b, S_d\n",
        "\n",
        "\n",
        "def last_trading_day(S_b: pd.Series, start: pd.Timestamp, end: pd.Timestamp) -> Optional[pd.Timestamp]:\n",
        "    \"\"\"Return the last business day in [start, end].\"\"\"\n",
        "    sl = S_b.loc[start:end]\n",
        "    return sl.index[-1] if not sl.empty else None\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Fine-tuning panel (1980–1999)\n",
        "# -----------------------------\n",
        "def load_finetune_fx_panel(url: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Load Norges Bank FX panel 1980–1999 for fine-tuning.\n",
        "\n",
        "    CSV format:\n",
        "      ds; AUD; CAD; CHF; DKK; GBP; ISK; JPY; NZD; SEK; USD; XDR\n",
        "\n",
        "    Returns:\n",
        "        df: index = DATE (daily), columns = FINETUNE_FX_COLS\n",
        "    \"\"\"\n",
        "    text = download_csv_text(url, CFG.retries, CFG.timeout)\n",
        "    raw = pd.read_csv(\n",
        "        io.StringIO(text),\n",
        "        sep=\";\",\n",
        "        decimal=\".\",\n",
        "        encoding=\"utf-8-sig\",\n",
        "    )\n",
        "\n",
        "    required = [\"ds\"] + FINETUNE_FX_COLS\n",
        "    missing = set(required) - set(raw.columns)\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing columns in fine-tune CSV: {missing}. Got: {list(raw.columns)}\")\n",
        "\n",
        "    df = (\n",
        "        raw[required]\n",
        "        .rename(columns={\"ds\": \"DATE\"})\n",
        "        .assign(DATE=lambda x: pd.to_datetime(x[\"DATE\"], dayfirst=True, errors=\"coerce\"))\n",
        "        .dropna(subset=[\"DATE\"])\n",
        "        .sort_values(\"DATE\")\n",
        "        .set_index(\"DATE\")\n",
        "    )\n",
        "\n",
        "    for col in FINETUNE_FX_COLS:\n",
        "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "\n",
        "    df = df.dropna(how=\"all\", subset=FINETUNE_FX_COLS)\n",
        "    return df\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Chronos-2: base pipeline + fine-tuning\n",
        "# -----------------------------\n",
        "def build_base_chronos_pipeline() -> BaseChronosPipeline:\n",
        "    \"\"\"Load the base Chronos-2 pipeline on CUDA (fp16).\"\"\"\n",
        "    if not torch.cuda.is_available():\n",
        "        raise SystemExit(\"CUDA not available. Please install a CUDA build of PyTorch and a recent NVIDIA driver.\")\n",
        "\n",
        "    pipeline: BaseChronosPipeline = BaseChronosPipeline.from_pretrained(\n",
        "        \"amazon/chronos-2\",\n",
        "        device_map=\"cuda\",\n",
        "        torch_dtype=torch.float16,\n",
        "    )\n",
        "    return pipeline\n",
        "\n",
        "\n",
        "def finetune_chronos_on_nb_panel(\n",
        "    pipeline: BaseChronosPipeline,\n",
        "    fx_panel: pd.DataFrame,\n",
        ") -> BaseChronosPipeline:\n",
        "    \"\"\"\n",
        "    Fine-tune Chronos-2 on the Norges Bank FX panel (1980–1999).\n",
        "\n",
        "    Each FX column (AUD, CAD, ..., XDR) is treated as a separate univariate series.\n",
        "    No covariates are used for fine-tuning (price-only panel).\n",
        "    \"\"\"\n",
        "    train_inputs: List[Dict] = []\n",
        "\n",
        "    for col in FINETUNE_FX_COLS:\n",
        "        series = fx_panel[col].dropna().astype(np.float32).values\n",
        "        if series.size < CFG.ft_prediction_length * 2:\n",
        "            continue\n",
        "\n",
        "        train_inputs.append(\n",
        "            {\n",
        "                \"target\": series,\n",
        "                \"past_covariates\": {},\n",
        "                \"future_covariates\": {},\n",
        "            }\n",
        "        )\n",
        "\n",
        "    if not train_inputs:\n",
        "        raise RuntimeError(\"No valid series found for fine-tuning.\")\n",
        "\n",
        "    if CFG.verbose:\n",
        "        total_len = sum(len(d[\"target\"]) for d in train_inputs)\n",
        "        print(\"\\n[Fine-tuning Chronos-2 on Norges Bank FX panel 1980–1999]\")\n",
        "        print(f\"  Number of series: {len(train_inputs)}\")\n",
        "        print(f\"  Total length across series: {total_len}\")\n",
        "        print(\n",
        "            f\"  prediction_length={CFG.ft_prediction_length}, \"\n",
        "            f\"num_steps={CFG.ft_num_steps}, lr={CFG.ft_learning_rate}, \"\n",
        "            f\"batch_size={CFG.ft_batch_size}\"\n",
        "        )\n",
        "\n",
        "    pipeline = pipeline.fit(\n",
        "        inputs=train_inputs,\n",
        "        prediction_length=CFG.ft_prediction_length,\n",
        "        num_steps=CFG.ft_num_steps,\n",
        "        learning_rate=CFG.ft_learning_rate,\n",
        "        batch_size=CFG.ft_batch_size,\n",
        "        logging_steps=CFG.ft_logging_steps,\n",
        "    )\n",
        "\n",
        "    return pipeline\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Chronos-2 univariate forecast function (multi-FX)\n",
        "# -----------------------------\n",
        "def build_model_chronos2_multi(\n",
        "    pipeline: BaseChronosPipeline,\n",
        "    max_context: int,\n",
        "    horizon_len: int,\n",
        ") -> Callable[[np.ndarray, int], np.ndarray]:\n",
        "    \"\"\"\n",
        "    Build a Chronos-2 forecasting function for generic univariate FX series.\n",
        "\n",
        "    Returns:\n",
        "        forecast_fn(x, H) -> np.ndarray length H (daily point forecast)\n",
        "    \"\"\"\n",
        "\n",
        "    def extract_median(pred: pd.DataFrame) -> np.ndarray:\n",
        "        \"\"\"Extract median forecast from Chronos output.\"\"\"\n",
        "        df = pred.copy()\n",
        "        if \"timestamp\" in df.columns:\n",
        "            df = df.sort_values(\"timestamp\")\n",
        "\n",
        "        if \"0.5\" in df.columns:\n",
        "            arr = df[\"0.5\"].to_numpy()\n",
        "        elif \"predictions\" in df.columns:\n",
        "            arr = df[\"predictions\"].to_numpy()\n",
        "        elif \"forecast\" in df.columns and \"quantile\" in df.columns:\n",
        "            df = df.loc[df[\"quantile\"] == 0.5].copy()\n",
        "            arr = df[\"forecast\"].to_numpy()\n",
        "        else:\n",
        "            for cand in (\"forecast\", \"p50\", \"median\", \"mean\"):\n",
        "                if cand in df.columns:\n",
        "                    arr = df[cand].to_numpy()\n",
        "                    break\n",
        "            else:\n",
        "                raise RuntimeError(f\"Chronos2 predict_df: unsupported schema. Columns={list(df.columns)}\")\n",
        "\n",
        "        return np.asarray(arr, dtype=float)\n",
        "\n",
        "    def forecast_fn(x: np.ndarray, H: int) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Forecast H daily steps ahead for a single univariate FX series.\n",
        "        \"\"\"\n",
        "        ctx = np.asarray(x, dtype=float).ravel()[-max_context:]\n",
        "        ts = pd.date_range(\"2000-01-01\", periods=len(ctx), freq=\"D\")\n",
        "\n",
        "        df = pd.DataFrame(\n",
        "            {\n",
        "                \"item_id\": \"series_1\",\n",
        "                \"timestamp\": ts,\n",
        "                \"target\": ctx,\n",
        "            }\n",
        "        )\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            pred = pipeline.predict_df(\n",
        "                df,\n",
        "                prediction_length=H,\n",
        "                quantile_levels=[0.5],\n",
        "                id_column=\"item_id\",\n",
        "                timestamp_column=\"timestamp\",\n",
        "                target=\"target\",\n",
        "            )\n",
        "\n",
        "        med = extract_median(pred)\n",
        "        return med[:H]\n",
        "\n",
        "    return forecast_fn\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Quarterly walk-forward (point forecasts only)\n",
        "# -----------------------------\n",
        "def walk_forward_quarterly(\n",
        "    S_b: pd.Series,\n",
        "    S_d: pd.Series,\n",
        "    forecast_fn: Callable[[np.ndarray, int], np.ndarray],\n",
        "    series_name: str,\n",
        "    start_period: Optional[pd.Period] = None,\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Quarterly walk-forward:\n",
        "      - Quarterly frequency given by CFG.q_freq (e.g. Q-DEC)\n",
        "      - Cut = last business day in previous quarter\n",
        "      - Forecast next quarter at daily frequency\n",
        "      - Aggregate to quarterly mean over business days\n",
        "\n",
        "    Only quarters >= start_period are evaluated if start_period is provided.\n",
        "    \"\"\"\n",
        "    first_q = pd.Period(S_b.index.min(), freq=CFG.q_freq)\n",
        "    last_q  = pd.Period(S_b.index.max(),  freq=CFG.q_freq)\n",
        "\n",
        "    if start_period is not None:\n",
        "        first_q = max(first_q, start_period)\n",
        "\n",
        "    quarters = pd.period_range(first_q, last_q, freq=CFG.q_freq)\n",
        "\n",
        "    rows: Dict = {}\n",
        "    dropped: Dict[str, str] = {}\n",
        "\n",
        "    for q in quarters:\n",
        "        prev_q = q - 1\n",
        "        q_start, q_end = q.start_time, q.end_time\n",
        "        prev_start, prev_end = prev_q.start_time, prev_q.end_time\n",
        "\n",
        "        cut = last_trading_day(S_b, prev_start, prev_end)\n",
        "        if cut is None:\n",
        "            dropped[str(q)] = \"no_cut_in_prev_q\"\n",
        "            continue\n",
        "\n",
        "        hist_d = S_d.loc[:cut]\n",
        "        if hist_d.size < CFG.min_hist_days:\n",
        "            dropped[str(q)] = f\"hist<{CFG.min_hist_days}\"\n",
        "            continue\n",
        "\n",
        "        idx_q_b = S_b.index[(S_b.index >= q_start) & (S_b.index <= q_end)]\n",
        "        if idx_q_b.size < 1:\n",
        "            dropped[str(q)] = \"no_bdays_in_q\"\n",
        "            continue\n",
        "        y_true = float(S_b.loc[idx_q_b].mean())\n",
        "\n",
        "        H = (q_end.date() - q_start.date()).days + 1\n",
        "        if H <= 0 or H > CFG.max_horizon:\n",
        "            dropped[str(q)] = f\"horizon_invalid(H={H})\"\n",
        "            continue\n",
        "\n",
        "        context = min(CFG.max_context, len(hist_d))\n",
        "        x = hist_d.values[-context:]\n",
        "\n",
        "        pf = forecast_fn(x, H)\n",
        "        if pf.shape[0] < H:\n",
        "            dropped[str(q)] = f\"horizon_short({pf.shape[0]})\"\n",
        "            continue\n",
        "\n",
        "        f_idx = pd.date_range(cut + pd.Timedelta(days=1), periods=H, freq=\"D\")\n",
        "        pred_daily = pd.Series(pf[:H], index=f_idx, name=\"point\")\n",
        "\n",
        "        pred_b = pred_daily.reindex(idx_q_b, method=None)\n",
        "        if pred_b.isna().all():\n",
        "            dropped[str(q)] = \"no_overlap_pred_B_days\"\n",
        "            continue\n",
        "        y_pred = float(pred_b.dropna().mean())\n",
        "\n",
        "        rows[str(q)] = {\n",
        "            \"series\": series_name,\n",
        "            \"quarter\": q,\n",
        "            \"cut\": cut,\n",
        "            \"y_true\": y_true,\n",
        "            \"y_pred\": y_pred,\n",
        "        }\n",
        "\n",
        "    df = pd.DataFrame.from_dict(rows, orient=\"index\")\n",
        "    if not df.empty:\n",
        "        df = df.set_index(\"quarter\").sort_index()\n",
        "\n",
        "    if CFG.verbose and dropped:\n",
        "        miss = [str(q) for q in quarters if q not in df.index]\n",
        "        if miss:\n",
        "            print(f\"[{series_name}] Dropped quarters:\")\n",
        "            for qq in miss:\n",
        "                print(f\"  {qq}: {dropped.get(qq, 'unknown')}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Evaluation & DM\n",
        "# -----------------------------\n",
        "def evaluate(eval_df: pd.DataFrame) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Compute RMSE, MAE, and directional accuracy for one FX series.\n",
        "    \"\"\"\n",
        "    df = eval_df.copy()\n",
        "    df[\"err\"] = df[\"y_true\"] - df[\"y_pred\"]\n",
        "    core = df.dropna(subset=[\"y_true\", \"y_pred\"]).copy()\n",
        "\n",
        "    n_obs = int(len(core))\n",
        "    rmse = float(np.sqrt(np.mean(np.square(core[\"err\"])))) if n_obs else np.nan\n",
        "    mae  = float(mean_absolute_error(core[\"y_true\"], core[\"y_pred\"])) if n_obs else np.nan\n",
        "\n",
        "    core[\"y_prev\"] = core[\"y_true\"].shift(1)\n",
        "    mask = core[\"y_prev\"].notna()\n",
        "    dir_true = np.sign(core.loc[mask, \"y_true\"] - core.loc[mask, \"y_prev\"])\n",
        "    dir_pred = np.sign(core.loc[mask, \"y_pred\"] - core.loc[mask, \"y_prev\"])\n",
        "    hits = int((dir_true.values == dir_pred.values).sum())\n",
        "    total = int(mask.sum())\n",
        "    hit_rate = (hits / total) if total else np.nan\n",
        "\n",
        "    if CFG.verbose:\n",
        "        if total:\n",
        "            print(\n",
        "                f\"Observations: {n_obs} | RMSE={rmse:.6f} | MAE={mae:.6f} | \"\n",
        "                f\"DirAcc={hits}/{total} ({hit_rate*100:.1f}%)\"\n",
        "            )\n",
        "        else:\n",
        "            print(\n",
        "                f\"Observations: {n_obs} | RMSE={rmse:.6f} | MAE={mae:.6f} | DirAcc=NA\"\n",
        "            )\n",
        "\n",
        "    return {\n",
        "        \"observations\": n_obs,\n",
        "        \"rmse\": rmse,\n",
        "        \"mae\": mae,\n",
        "        \"dir_hits\": hits,\n",
        "        \"dir_total\": total,\n",
        "        \"dir_acc\": hit_rate if total else np.nan,\n",
        "    }\n",
        "\n",
        "\n",
        "def _normal_cdf(z: float) -> float:\n",
        "    \"\"\"Standard normal CDF without SciPy.\"\"\"\n",
        "    return 0.5 * (1.0 + math.erf(z / math.sqrt(2.0)))\n",
        "\n",
        "\n",
        "def dm_test(y_true: pd.Series, y_model: pd.Series, y_rw: pd.Series, h: int = 1, loss: str = \"mse\"):\n",
        "    \"\"\"\n",
        "    Diebold–Mariano test for equal predictive accuracy vs random walk.\n",
        "    \"\"\"\n",
        "    df = pd.concat({\"y\": y_true, \"m\": y_model, \"rw\": y_rw}, axis=1).dropna()\n",
        "    if df.empty or len(df) < 5:\n",
        "        return float(\"nan\"), float(\"nan\")\n",
        "    e_m = df[\"y\"] - df[\"m\"]\n",
        "    e_r = df[\"y\"] - df[\"rw\"]\n",
        "    d = np.abs(e_m) - np.abs(e_r) if loss.lower() == \"mae\" else (e_m**2) - (e_r**2)\n",
        "    N = int(len(d))\n",
        "    d_mean = float(d.mean())\n",
        "    gamma0 = float(np.var(d, ddof=1)) if N > 1 else 0.0\n",
        "    var_bar = gamma0 / N\n",
        "    if h > 1 and N > 2:\n",
        "        for k in range(1, min(h - 1, N - 1) + 1):\n",
        "            w_k = 1.0 - k / h\n",
        "            cov_k = float(np.cov(d[k:], d[:-k], ddof=1)[0, 1])\n",
        "            var_bar += 2.0 * w_k * cov_k / N\n",
        "    if var_bar <= 0 or not np.isfinite(var_bar):\n",
        "        return float(\"nan\"), float(\"nan\")\n",
        "    dm_stat = d_mean / math.sqrt(var_bar)\n",
        "    p_val = 2.0 * (1.0 - _normal_cdf(abs(dm_stat)))\n",
        "    return dm_stat, p_val\n",
        "\n",
        "\n",
        "def evaluate_with_dm(eval_df: pd.DataFrame) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Wrapper to compute metrics + DM test vs random walk.\n",
        "    Random walk benchmark: previous quarter's observed level.\n",
        "    \"\"\"\n",
        "    m = evaluate(eval_df)\n",
        "    df = eval_df.copy()\n",
        "    df[\"rw_pred\"] = df[\"y_true\"].shift(1)\n",
        "    dm_stat, p_val = dm_test(df[\"y_true\"], df[\"y_pred\"], df[\"rw_pred\"], h=1, loss=\"mse\")\n",
        "    m[\"dm_stat\"] = float(dm_stat) if np.isfinite(dm_stat) else np.nan\n",
        "    m[\"dm_pvalue\"] = float(p_val) if np.isfinite(p_val) else np.nan\n",
        "    return m\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Main\n",
        "# -----------------------------\n",
        "def main():\n",
        "    # 1) Load evaluation frame (multi-FX)\n",
        "    df_d = load_multi_fx(CFG.url_multi)\n",
        "    all_cols = [c for c in df_d.columns if pd.api.types.is_numeric_dtype(df_d[c])]\n",
        "\n",
        "    if CFG.include_fx:\n",
        "        fx_cols = [c for c in CFG.include_fx if c in all_cols]\n",
        "    else:\n",
        "        fx_cols = all_cols  # includes I44, XDR, etc., if present\n",
        "\n",
        "    # 2) Load fine-tuning panel and fine-tune Chronos-2\n",
        "    fx_panel = load_finetune_fx_panel(CFG.url_finetune)\n",
        "    ft_start = fx_panel.index.min()\n",
        "    ft_end = fx_panel.index.max()\n",
        "\n",
        "    if CFG.verbose:\n",
        "        print(f\"\\nFine-tune panel: {ft_start.date()} → {ft_end.date()} | n={len(fx_panel)}\")\n",
        "        print(f\"Fine-tune FX columns: {FINETUNE_FX_COLS}\")\n",
        "\n",
        "    base_pipeline = build_base_chronos_pipeline()\n",
        "    ft_pipeline = finetune_chronos_on_nb_panel(base_pipeline, fx_panel)\n",
        "\n",
        "    # 3) Define evaluation start period as the first quarter AFTER fine-tune end quarter\n",
        "    #    Example: fine-tune ends 1999-12-31 (Q4-1999) → eval starts from 2000Q1\n",
        "    eval_start_period = pd.Period(ft_end, freq=CFG.q_freq) + 1\n",
        "    if CFG.verbose:\n",
        "        print(f\"\\nEvaluation starts from quarter: {eval_start_period} (i.e., strictly after fine-tune period)\")\n",
        "\n",
        "    # 4) Build forecasting function based on fine-tuned pipeline\n",
        "    forecast_fn = build_model_chronos2_multi(\n",
        "        pipeline=ft_pipeline,\n",
        "        max_context=CFG.max_context,\n",
        "        horizon_len=CFG.max_horizon,\n",
        "    )\n",
        "\n",
        "    if CFG.verbose:\n",
        "        print(f\"\\nRunning quarterly walk-forward for {len(fx_cols)} series:\", fx_cols)\n",
        "\n",
        "    # 5) Walk-forward and metrics per FX series (only quarters >= eval_start_period)\n",
        "    metrics_rows = []\n",
        "\n",
        "    for col in fx_cols:\n",
        "        S_b, S_d = series_daily_and_b(df_d, col)\n",
        "        if CFG.verbose:\n",
        "            print(f\"\\n[{col}] Data (B): {S_b.index.min().date()} → {S_b.index.max().date()} | n={len(S_b)}\")\n",
        "\n",
        "        df_eval = walk_forward_quarterly(\n",
        "            S_b=S_b,\n",
        "            S_d=S_d,\n",
        "            forecast_fn=forecast_fn,\n",
        "            series_name=col,\n",
        "            start_period=eval_start_period,\n",
        "        )\n",
        "\n",
        "        if df_eval.empty or df_eval[\"y_pred\"].isna().all():\n",
        "            if CFG.verbose:\n",
        "                print(f\"[{col}] No evaluable quarters after fine-tune period; skipping.\")\n",
        "            continue\n",
        "\n",
        "        m = evaluate_with_dm(df_eval)\n",
        "        m[\"series\"] = col\n",
        "        metrics_rows.append(m)\n",
        "\n",
        "        # Console summary per series\n",
        "        if np.isfinite(m[\"dir_acc\"]) and m[\"dir_total\"] > 0:\n",
        "            print(\n",
        "                f\"[{col}] Obs={m['observations']}, RMSE={m['rmse']:.4f}, MAE={m['mae']:.4f}, \"\n",
        "                f\"DirAcc={m['dir_hits']}/{m['dir_total']} ({m['dir_acc']*100:.1f}%), \"\n",
        "                f\"DM={m['dm_stat']:.3f}, p={m['dm_pvalue']:.4f}\"\n",
        "            )\n",
        "        else:\n",
        "            print(\n",
        "                f\"[{col}] Obs={m['observations']}, RMSE={m['rmse']:.4f}, MAE={m['mae']:.4f}, \"\n",
        "                f\"DirAcc=NA, DM={m['dm_stat']:.3f}, p={m['dm_pvalue']:.4f}\"\n",
        "            )\n",
        "\n",
        "    # 6) Save metrics\n",
        "    if not metrics_rows:\n",
        "        print(\"No series produced metrics after the fine-tune period. Check data and settings.\")\n",
        "        return\n",
        "\n",
        "    metrics_df = pd.DataFrame(metrics_rows)[\n",
        "        [\"series\", \"observations\", \"rmse\", \"mae\", \"dir_hits\", \"dir_total\", \"dir_acc\", \"dm_stat\", \"dm_pvalue\"]\n",
        "    ].sort_values(\"rmse\")\n",
        "    metrics_df.to_csv(CFG.metrics_csv, index=False, encoding=\"utf-8-sig\")\n",
        "    print(f\"\\nSaved metrics to: {CFG.metrics_csv}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "C4Jc-C2tA-i7",
        "outputId": "d7c3b0b5-5894-477e-b33d-db97a7aff77a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fine-tune panel: 1980-12-10 → 1999-12-31 | n=4930\n",
            "Fine-tune FX columns: ['AUD', 'CAD', 'CHF', 'DKK', 'GBP', 'ISK', 'JPY', 'NZD', 'SEK', 'USD', 'XDR']\n",
            "\n",
            "[Fine-tuning Chronos-2 on Norges Bank FX panel 1980–1999]\n",
            "  Number of series: 11\n",
            "  Total length across series: 52815\n",
            "  prediction_length=32, num_steps=50, lr=1e-05, batch_size=2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3451036838.py:262: FutureWarning: Fine-tuning support is experimental and may be changed in future versions.\n",
            "  pipeline = pipeline.fit(\n",
            "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50/50 00:06, Epoch 1/9223372036854775807]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.024800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>2.704700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.760400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.748100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.498000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation starts from quarter: 2000Q1 (i.e., strictly after fine-tune period)\n",
            "\n",
            "Running quarterly walk-forward for 19 series: ['I44', 'AUD', 'EUR', 'CAD', 'GBP', 'HKD', 'JPY', 'MYR', 'NZD', 'SGD', 'SEK', 'PLN', 'USD', 'PHP', 'IDR', 'KRW', 'THB', 'TWD', 'XDR']\n",
            "\n",
            "[I44] Data (B): 1999-01-04 → 2024-12-12 | n=6769\n",
            "Observations: 100 | RMSE=2.435872 | MAE=1.319355 | DirAcc=57/99 (57.6%)\n",
            "[I44] Obs=100, RMSE=2.4359, MAE=1.3194, DirAcc=57/99 (57.6%), DM=1.444, p=0.1486\n",
            "\n",
            "[AUD] Data (B): 1999-01-04 → 2024-12-12 | n=6769\n",
            "Observations: 100 | RMSE=0.166848 | MAE=0.081951 | DirAcc=57/99 (57.6%)\n",
            "[AUD] Obs=100, RMSE=0.1668, MAE=0.0820, DirAcc=57/99 (57.6%), DM=1.239, p=0.2152\n",
            "\n",
            "[EUR] Data (B): 1999-01-04 → 2024-12-12 | n=6769\n",
            "Observations: 100 | RMSE=0.232278 | MAE=0.115882 | DirAcc=64/99 (64.6%)\n",
            "[EUR] Obs=100, RMSE=0.2323, MAE=0.1159, DirAcc=64/99 (64.6%), DM=0.695, p=0.4870\n",
            "\n",
            "[CAD] Data (B): 1999-01-04 → 2024-12-12 | n=6769\n",
            "Observations: 100 | RMSE=0.167507 | MAE=0.083291 | DirAcc=57/99 (57.6%)\n",
            "[CAD] Obs=100, RMSE=0.1675, MAE=0.0833, DirAcc=57/99 (57.6%), DM=0.867, p=0.3859\n",
            "\n",
            "[GBP] Data (B): 1999-01-04 → 2024-12-12 | n=6769\n",
            "Observations: 100 | RMSE=0.462443 | MAE=0.203985 | DirAcc=53/99 (53.5%)\n",
            "[GBP] Obs=100, RMSE=0.4624, MAE=0.2040, DirAcc=53/99 (53.5%), DM=0.967, p=0.3334\n",
            "\n",
            "[HKD] Data (B): 1999-01-04 → 2024-12-12 | n=6769\n",
            "Observations: 100 | RMSE=0.043605 | MAE=0.022035 | DirAcc=45/99 (45.5%)\n",
            "[HKD] Obs=100, RMSE=0.0436, MAE=0.0220, DirAcc=45/99 (45.5%), DM=0.877, p=0.3807\n",
            "\n",
            "[JPY] Data (B): 1999-01-04 → 2024-12-12 | n=6769\n",
            "Observations: 100 | RMSE=0.338353 | MAE=0.163823 | DirAcc=58/99 (58.6%)\n",
            "[JPY] Obs=100, RMSE=0.3384, MAE=0.1638, DirAcc=58/99 (58.6%), DM=0.840, p=0.4011\n",
            "\n",
            "[MYR] Data (B): 1999-01-04 → 2024-12-12 | n=6769\n",
            "Observations: 100 | RMSE=0.065271 | MAE=0.033413 | DirAcc=57/99 (57.6%)\n",
            "[MYR] Obs=100, RMSE=0.0653, MAE=0.0334, DirAcc=57/99 (57.6%), DM=0.527, p=0.5984\n",
            "\n",
            "[NZD] Data (B): 1999-01-04 → 2024-12-12 | n=6769\n",
            "Observations: 100 | RMSE=0.142741 | MAE=0.077906 | DirAcc=62/99 (62.6%)\n",
            "[NZD] Obs=100, RMSE=0.1427, MAE=0.0779, DirAcc=62/99 (62.6%), DM=1.709, p=0.0875\n",
            "\n",
            "[SGD] Data (B): 1999-01-04 → 2024-12-12 | n=6769\n",
            "Observations: 100 | RMSE=0.179312 | MAE=0.097424 | DirAcc=45/99 (45.5%)\n",
            "[SGD] Obs=100, RMSE=0.1793, MAE=0.0974, DirAcc=45/99 (45.5%), DM=-0.202, p=0.8400\n",
            "\n",
            "[SEK] Data (B): 1999-01-04 → 2024-12-12 | n=6769\n",
            "Observations: 100 | RMSE=2.388623 | MAE=1.294348 | DirAcc=59/99 (59.6%)\n",
            "[SEK] Obs=100, RMSE=2.3886, MAE=1.2943, DirAcc=59/99 (59.6%), DM=0.930, p=0.3523\n",
            "\n",
            "[PLN] Data (B): 1999-01-04 → 2024-12-12 | n=6769\n",
            "Observations: 100 | RMSE=0.083886 | MAE=0.040796 | DirAcc=62/99 (62.6%)\n",
            "[PLN] Obs=100, RMSE=0.0839, MAE=0.0408, DirAcc=62/99 (62.6%), DM=1.265, p=0.2058\n",
            "\n",
            "[USD] Data (B): 1999-01-04 → 2024-12-12 | n=6769\n",
            "Observations: 100 | RMSE=0.338176 | MAE=0.169549 | DirAcc=51/99 (51.5%)\n",
            "[USD] Obs=100, RMSE=0.3382, MAE=0.1695, DirAcc=51/99 (51.5%), DM=0.918, p=0.3587\n",
            "\n",
            "[PHP] Data (B): 1999-01-04 → 2024-12-12 | n=6769\n",
            "Observations: 100 | RMSE=0.632467 | MAE=0.357680 | DirAcc=53/99 (53.5%)\n",
            "[PHP] Obs=100, RMSE=0.6325, MAE=0.3577, DirAcc=53/99 (53.5%), DM=0.414, p=0.6790\n",
            "\n",
            "[IDR] Data (B): 1999-01-04 → 2024-12-12 | n=6769\n",
            "Observations: 100 | RMSE=0.002929 | MAE=0.001566 | DirAcc=61/99 (61.6%)\n",
            "[IDR] Obs=100, RMSE=0.0029, MAE=0.0016, DirAcc=61/99 (61.6%), DM=1.369, p=0.1711\n",
            "\n",
            "[KRW] Data (B): 1999-01-04 → 2024-12-12 | n=6769\n",
            "Observations: 100 | RMSE=0.025694 | MAE=0.014166 | DirAcc=61/99 (61.6%)\n",
            "[KRW] Obs=100, RMSE=0.0257, MAE=0.0142, DirAcc=61/99 (61.6%), DM=0.067, p=0.9468\n",
            "\n",
            "[THB] Data (B): 1999-01-04 → 2024-12-12 | n=6769\n",
            "Observations: 100 | RMSE=0.818173 | MAE=0.438923 | DirAcc=50/99 (50.5%)\n",
            "[THB] Obs=100, RMSE=0.8182, MAE=0.4389, DirAcc=50/99 (50.5%), DM=1.456, p=0.1453\n",
            "\n",
            "[TWD] Data (B): 1999-01-04 → 2024-12-12 | n=6769\n",
            "Observations: 100 | RMSE=0.887137 | MAE=0.473744 | DirAcc=47/99 (47.5%)\n",
            "[TWD] Obs=100, RMSE=0.8871, MAE=0.4737, DirAcc=47/99 (47.5%), DM=-0.251, p=0.8021\n",
            "\n",
            "[XDR] Data (B): 1999-01-04 → 2024-12-12 | n=6769\n",
            "Observations: 100 | RMSE=0.346144 | MAE=0.180197 | DirAcc=56/99 (56.6%)\n",
            "[XDR] Obs=100, RMSE=0.3461, MAE=0.1802, DirAcc=56/99 (56.6%), DM=0.933, p=0.3510\n",
            "\n",
            "Saved metrics to: FX_Chronos2_finetuned_metrics_quarterly.csv\n"
          ]
        }
      ]
    }
  ]
}