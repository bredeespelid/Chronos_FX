{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "gpu"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Chronos_Fx-Price Finetuned Multi M\n"
      ],
      "metadata": {
        "id": "uWevYQyV_WWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install chronos-forecasting"
      ],
      "metadata": {
        "id": "0jlxEGfl_WWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from chronos import BaseChronosPipeline\n",
        "\n",
        "pipeline = BaseChronosPipeline.from_pretrained(\"amazon/chronos-2\", device_map=\"cuda\")\n"
      ],
      "metadata": {
        "id": "DFZHJLH__WWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Chronos-2 – Multi-FX walk-forward (monthly, levels) with fine-tuning,\n",
        "evaluation starts strictly after the fine-tuning period.\n",
        "\n",
        "Pipeline:\n",
        "1) Fine-tune Chronos-2 on Norges Bank FX panel (1980–1999):\n",
        "      NB1980-1999.csv with columns:\n",
        "      ds; AUD; CAD; CHF; DKK; GBP; ISK; JPY; NZD; SEK; USD; XDR\n",
        "\n",
        "2) Evaluate on MultiFXData.csv (price-only), but only for months\n",
        "   strictly after the fine-tune end date:\n",
        "   - Cut: last business day of previous month\n",
        "   - Forecast: next calendar month at daily frequency\n",
        "   - Aggregate to monthly mean over business days\n",
        "   - Per FX series: Observations, RMSE, MAE, Directional Accuracy,\n",
        "                    DM test vs Random Walk (MSE, h=1)\n",
        "   - Output: metrics CSV (one row per FX series)\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "import io, time, math\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, Tuple, Dict, Callable, List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests, certifi\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "import torch\n",
        "from chronos import BaseChronosPipeline  # chronos-forecasting>=2.0\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Configuration\n",
        "# -----------------------------\n",
        "@dataclass\n",
        "class Config:\n",
        "    # Evaluation data (multi-FX)\n",
        "    url_multi: str = (\n",
        "        \"https://raw.githubusercontent.com/bredeespelid/\"\n",
        "        \"Data_MasterOppgave/refs/heads/main/EURNOK/MultiFXData.csv\"\n",
        "    )\n",
        "    # Fine-tuning panel (Norges Bank 1980–1999)\n",
        "    url_finetune: str = (\n",
        "        \"https://raw.githubusercontent.com/bredeespelid/\"\n",
        "        \"Data_MasterOppgave/refs/heads/main/FineTuneData/NB1980-1999.csv\"\n",
        "    )\n",
        "\n",
        "    m_freq: str = \"M\"           # monthly periods, month-end\n",
        "    min_hist_days: int = 40\n",
        "    max_context: int = 2048\n",
        "    max_horizon: int = 64       # must exceed longest month\n",
        "    retries: int = 3\n",
        "    timeout: int = 60\n",
        "    verbose: bool = True\n",
        "    metrics_csv: str = \"FX_Chronos2_finetuned_metrics_monthly_postFT.csv\"\n",
        "    include_fx: Optional[List[str]] = None  # e.g. [\"EUR\", \"USD\", \"SEK\", \"DKK\", \"GBP\"]\n",
        "\n",
        "    # Fine-tuning hyperparameters\n",
        "    ft_prediction_length: int = 32\n",
        "    ft_num_steps: int = 50\n",
        "    ft_learning_rate: float = 1e-5\n",
        "    ft_batch_size: int = 2\n",
        "    ft_logging_steps: int = 10\n",
        "\n",
        "\n",
        "CFG = Config()\n",
        "\n",
        "# FX columns used for fine-tuning\n",
        "FINETUNE_FX_COLS = [\n",
        "    \"AUD\", \"CAD\", \"CHF\", \"DKK\", \"GBP\",\n",
        "    \"ISK\", \"JPY\", \"NZD\", \"SEK\", \"USD\", \"XDR\",\n",
        "]\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Helper: download CSV with retries\n",
        "# -----------------------------\n",
        "def download_csv_text(url: str, retries: int, timeout: int) -> str:\n",
        "    \"\"\"Download text from URL with retry/backoff logic.\"\"\"\n",
        "    last_err = None\n",
        "    for k in range(1, retries + 1):\n",
        "        try:\n",
        "            r = requests.get(url, timeout=timeout, verify=certifi.where())\n",
        "            r.raise_for_status()\n",
        "            return r.text\n",
        "        except Exception as e:\n",
        "            last_err = e\n",
        "            if k < retries:\n",
        "                wait = 1.5 * k\n",
        "                print(f\"[warning] Download failed ({k}/{retries}): {e}. Retrying in {wait:.1f}s...\")\n",
        "                time.sleep(wait)\n",
        "    raise RuntimeError(f\"Download failed: {last_err}\")\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Load Multi-FX evaluation data\n",
        "# -----------------------------\n",
        "def load_multi_fx(url: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Load MultiFXData.csv with columns like:\n",
        "      DATE, I44, AUD, CHF, DKK, EUR, CAD, GBP, ..., USD, ...\n",
        "\n",
        "    Robust to:\n",
        "      - comma/semicolon separators\n",
        "      - dot/comma decimals\n",
        "\n",
        "    Returns:\n",
        "        Daily DataFrame indexed by DATE, numeric columns forward-filled.\n",
        "    \"\"\"\n",
        "    text = download_csv_text(url, CFG.retries, CFG.timeout)\n",
        "\n",
        "    def _try_read(sep: str, decimal: str) -> pd.DataFrame:\n",
        "        return pd.read_csv(io.StringIO(text), sep=sep, encoding=\"utf-8-sig\", decimal=decimal)\n",
        "\n",
        "    # First attempt: comma + dot decimals\n",
        "    raw = _try_read(\",\", \".\")\n",
        "    if \"DATE\" not in raw.columns:\n",
        "        # Second attempt: semicolon + dot decimals\n",
        "        raw = _try_read(\";\", \".\")\n",
        "    if \"DATE\" not in raw.columns:\n",
        "        # Fallback: comma/semicolon + comma decimals\n",
        "        for sep in (\",\", \";\"):\n",
        "            raw = _try_read(sep, \",\")\n",
        "            if \"DATE\" in raw.columns:\n",
        "                break\n",
        "\n",
        "    if \"DATE\" not in raw.columns:\n",
        "        raise ValueError(f\"Expected a DATE column; got: {list(raw.columns)[:10]} ...\")\n",
        "\n",
        "    raw[\"DATE\"] = pd.to_datetime(raw[\"DATE\"], errors=\"coerce\")\n",
        "    raw = raw.dropna(subset=[\"DATE\"]).sort_values(\"DATE\").set_index(\"DATE\")\n",
        "\n",
        "    num_df = raw.apply(pd.to_numeric, errors=\"coerce\")\n",
        "    daily_idx = pd.date_range(num_df.index.min(), num_df.index.max(), freq=\"D\")\n",
        "    df_d = num_df.reindex(daily_idx).ffill()\n",
        "    df_d.index.name = \"DATE\"\n",
        "    return df_d\n",
        "\n",
        "\n",
        "def series_daily_and_b(df_d: pd.DataFrame, col: str) -> Tuple[pd.Series, pd.Series]:\n",
        "    \"\"\"\n",
        "    Extract one FX series from the multi-frame.\n",
        "\n",
        "    Returns:\n",
        "        S_b: business-day series (B, forward-filled)\n",
        "        S_d: calendar-day series (D)\n",
        "    \"\"\"\n",
        "    if col not in df_d.columns:\n",
        "        raise ValueError(f\"Column {col} not found in MultiFXData.\")\n",
        "    S_d = df_d[col].astype(float)\n",
        "    S_d.name = col\n",
        "    S_b = S_d.asfreq(\"B\").ffill()\n",
        "    S_b.name = col\n",
        "    return S_b, S_d\n",
        "\n",
        "\n",
        "def last_trading_day(S_b: pd.Series, start: pd.Timestamp, end: pd.Timestamp) -> Optional[pd.Timestamp]:\n",
        "    \"\"\"Return the last business day in [start, end].\"\"\"\n",
        "    sl = S_b.loc[start:end]\n",
        "    return sl.index[-1] if not sl.empty else None\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Load fine-tuning FX panel (1980–1999)\n",
        "# -----------------------------\n",
        "def load_finetune_fx_panel(url: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Load Norges Bank FX panel 1980–1999 for fine-tuning.\n",
        "\n",
        "    CSV format:\n",
        "      ds; AUD; CAD; CHF; DKK; GBP; ISK; JPY; NZD; SEK; USD; XDR\n",
        "\n",
        "    Returns:\n",
        "        df: index = DATE (daily), columns = FINETUNE_FX_COLS\n",
        "    \"\"\"\n",
        "    text = download_csv_text(url, CFG.retries, CFG.timeout)\n",
        "    raw = pd.read_csv(\n",
        "        io.StringIO(text),\n",
        "        sep=\";\",\n",
        "        decimal=\".\",\n",
        "        encoding=\"utf-8-sig\",\n",
        "    )\n",
        "\n",
        "    required = [\"ds\"] + FINETUNE_FX_COLS\n",
        "    missing = set(required) - set(raw.columns)\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing columns in fine-tune CSV: {missing}. Got: {list(raw.columns)}\")\n",
        "\n",
        "    df = (\n",
        "        raw[required]\n",
        "        .rename(columns={\"ds\": \"DATE\"})\n",
        "        .assign(DATE=lambda x: pd.to_datetime(x[\"DATE\"], dayfirst=True, errors=\"coerce\"))\n",
        "        .dropna(subset=[\"DATE\"])\n",
        "        .sort_values(\"DATE\")\n",
        "        .set_index(\"DATE\")\n",
        "    )\n",
        "\n",
        "    for col in FINETUNE_FX_COLS:\n",
        "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "\n",
        "    df = df.dropna(how=\"all\", subset=FINETUNE_FX_COLS)\n",
        "    return df\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Chronos-2: base pipeline + fine-tuning\n",
        "# -----------------------------\n",
        "def build_base_chronos_pipeline() -> BaseChronosPipeline:\n",
        "    \"\"\"Load the base Chronos-2 pipeline on CUDA (fp16).\"\"\"\n",
        "    if not torch.cuda.is_available():\n",
        "        raise SystemExit(\"CUDA not available. Please install a CUDA build of PyTorch and a recent NVIDIA driver.\")\n",
        "\n",
        "    pipeline: BaseChronosPipeline = BaseChronosPipeline.from_pretrained(\n",
        "        \"amazon/chronos-2\",\n",
        "        device_map=\"cuda\",\n",
        "        torch_dtype=torch.float16,\n",
        "    )\n",
        "    return pipeline\n",
        "\n",
        "\n",
        "def finetune_chronos_on_nb_panel(\n",
        "    pipeline: BaseChronosPipeline,\n",
        "    fx_panel: pd.DataFrame,\n",
        ") -> BaseChronosPipeline:\n",
        "    \"\"\"\n",
        "    Fine-tune Chronos-2 on the Norges Bank FX panel (1980–1999).\n",
        "\n",
        "    Each FX column (AUD, CAD, ..., XDR) is treated as a separate univariate series.\n",
        "    No covariates are used for fine-tuning (price-only panel).\n",
        "    \"\"\"\n",
        "    train_inputs: List[Dict] = []\n",
        "\n",
        "    for col in FINETUNE_FX_COLS:\n",
        "        series = fx_panel[col].dropna().astype(np.float32).values\n",
        "        if series.size < CFG.ft_prediction_length * 2:\n",
        "            continue\n",
        "\n",
        "        train_inputs.append(\n",
        "            {\n",
        "                \"target\": series,\n",
        "                \"past_covariates\": {},\n",
        "                \"future_covariates\": {},\n",
        "            }\n",
        "        )\n",
        "\n",
        "    if not train_inputs:\n",
        "        raise RuntimeError(\"No valid series found for fine-tuning.\")\n",
        "\n",
        "    if CFG.verbose:\n",
        "        total_len = sum(len(d[\"target\"]) for d in train_inputs)\n",
        "        print(\"\\n[Fine-tuning Chronos-2 on Norges Bank FX panel 1980–1999]\")\n",
        "        print(f\"  Number of series: {len(train_inputs)}\")\n",
        "        print(f\"  Total length across series: {total_len}\")\n",
        "        print(\n",
        "            f\"  prediction_length={CFG.ft_prediction_length}, \"\n",
        "            f\"num_steps={CFG.ft_num_steps}, lr={CFG.ft_learning_rate}, \"\n",
        "            f\"batch_size={CFG.ft_batch_size}\"\n",
        "        )\n",
        "\n",
        "    pipeline = pipeline.fit(\n",
        "        inputs=train_inputs,\n",
        "        prediction_length=CFG.ft_prediction_length,\n",
        "        num_steps=CFG.ft_num_steps,\n",
        "        learning_rate=CFG.ft_learning_rate,\n",
        "        batch_size=CFG.ft_batch_size,\n",
        "        logging_steps=CFG.ft_logging_steps,\n",
        "    )\n",
        "\n",
        "    return pipeline\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Chronos-2 model builder (multi-FX, point forecasts only)\n",
        "# -----------------------------\n",
        "def build_model_chronos2_multi(\n",
        "    pipeline: BaseChronosPipeline,\n",
        "    max_context: int,\n",
        "    horizon_len: int,\n",
        ") -> Callable[[np.ndarray, int], np.ndarray]:\n",
        "    \"\"\"\n",
        "    Build a Chronos-2 forecasting function for generic univariate FX series.\n",
        "\n",
        "    Returns:\n",
        "        forecast_fn(x, H) -> np.ndarray length H (daily point forecast)\n",
        "    \"\"\"\n",
        "\n",
        "    def extract_median(pred: pd.DataFrame) -> np.ndarray:\n",
        "        \"\"\"Extract median forecast from Chronos output.\"\"\"\n",
        "        df = pred.copy()\n",
        "        if \"timestamp\" in df.columns:\n",
        "            df = df.sort_values(\"timestamp\")\n",
        "\n",
        "        if \"0.5\" in df.columns:\n",
        "            arr = df[\"0.5\"].to_numpy()\n",
        "        elif \"predictions\" in df.columns:\n",
        "            arr = df[\"predictions\"].to_numpy()\n",
        "        elif \"forecast\" in df.columns and \"quantile\" in df.columns:\n",
        "            df = df.loc[df[\"quantile\"] == 0.5].copy()\n",
        "            arr = df[\"forecast\"].to_numpy()\n",
        "        else:\n",
        "            for cand in (\"forecast\", \"p50\", \"median\", \"mean\"):\n",
        "                if cand in df.columns:\n",
        "                    arr = df[cand].to_numpy()\n",
        "                    break\n",
        "            else:\n",
        "                raise RuntimeError(f\"Chronos2 predict_df: unsupported schema. Columns={list(df.columns)}\")\n",
        "\n",
        "        return np.asarray(arr, dtype=float)\n",
        "\n",
        "    def forecast_fn(x: np.ndarray, H: int) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Forecast H daily steps ahead for a single univariate FX series.\n",
        "        \"\"\"\n",
        "        ctx = np.asarray(x, dtype=float).ravel()[-max_context:]\n",
        "        ts = pd.date_range(\"2000-01-01\", periods=len(ctx), freq=\"D\")\n",
        "\n",
        "        df = pd.DataFrame(\n",
        "            {\n",
        "                \"item_id\": \"series_1\",\n",
        "                \"timestamp\": ts,\n",
        "                \"target\": ctx,\n",
        "            }\n",
        "        )\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            pred = pipeline.predict_df(\n",
        "                df,\n",
        "                prediction_length=H,\n",
        "                quantile_levels=[0.5],\n",
        "                id_column=\"item_id\",\n",
        "                timestamp_column=\"timestamp\",\n",
        "                target=\"target\",\n",
        "            )\n",
        "\n",
        "        med = extract_median(pred)\n",
        "        return med[:H]\n",
        "\n",
        "    return forecast_fn\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Monthly walk-forward for one FX series (with start_period)\n",
        "# -----------------------------\n",
        "def walk_forward_monthly(\n",
        "    S_b: pd.Series,\n",
        "    S_d: pd.Series,\n",
        "    forecast_fn: Callable[[np.ndarray, int], np.ndarray],\n",
        "    series_name: str,\n",
        "    start_period: Optional[pd.Period] = None,\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Monthly walk-forward:\n",
        "      - Cut = last B-day in previous month\n",
        "      - Forecast next month at daily frequency\n",
        "      - Aggregate to monthly mean over business days\n",
        "\n",
        "    Only months >= start_period are evaluated if start_period is provided.\n",
        "    \"\"\"\n",
        "    first_m = pd.Period(S_b.index.min(), freq=CFG.m_freq)\n",
        "    last_m  = pd.Period(S_b.index.max(),  freq=CFG.m_freq)\n",
        "\n",
        "    if start_period is not None:\n",
        "        # Ensure we start no earlier than the requested evaluation period.\n",
        "        first_m = max(first_m, start_period)\n",
        "\n",
        "    months = pd.period_range(first_m, last_m, freq=CFG.m_freq)\n",
        "\n",
        "    rows: Dict = {}\n",
        "    dropped: Dict[str, str] = {}\n",
        "\n",
        "    for m in months:\n",
        "        prev_m = m - 1\n",
        "        m_start, m_end = m.start_time, m.end_time\n",
        "        prev_start, prev_end = prev_m.start_time, prev_m.end_time\n",
        "\n",
        "        cut = last_trading_day(S_b, prev_start, prev_end)\n",
        "        if cut is None:\n",
        "            dropped[str(m)] = \"no_cut_in_prev_m\"\n",
        "            continue\n",
        "\n",
        "        hist_d = S_d.loc[:cut]\n",
        "        if hist_d.size < CFG.min_hist_days:\n",
        "            dropped[str(m)] = f\"hist<{CFG.min_hist_days}\"\n",
        "            continue\n",
        "\n",
        "        idx_m_b = S_b.index[(S_b.index >= m_start) & (S_b.index <= m_end)]\n",
        "        if idx_m_b.size < 1:\n",
        "            dropped[str(m)] = \"no_bdays_in_m\"\n",
        "            continue\n",
        "        y_true = float(S_b.loc[idx_m_b].mean())\n",
        "\n",
        "        H = (m_end.date() - m_start.date()).days + 1\n",
        "        if H <= 0 or H > CFG.max_horizon:\n",
        "            dropped[str(m)] = f\"horizon_invalid(H={H})\"\n",
        "            continue\n",
        "\n",
        "        context = min(CFG.max_context, len(hist_d))\n",
        "        x = hist_d.values[-context:]\n",
        "\n",
        "        pf = forecast_fn(x, H)\n",
        "        if pf.shape[0] < H:\n",
        "            dropped[str(m)] = f\"horizon_short({pf.shape[0]})\"\n",
        "            continue\n",
        "\n",
        "        f_idx = pd.date_range(cut + pd.Timedelta(days=1), periods=H, freq=\"D\")\n",
        "        pred_daily = pd.Series(pf[:H], index=f_idx, name=\"point\")\n",
        "\n",
        "        pred_b = pred_daily.reindex(idx_m_b, method=None)\n",
        "        if pred_b.isna().all():\n",
        "            dropped[str(m)] = \"no_overlap_pred_B_days\"\n",
        "            continue\n",
        "        y_pred = float(pred_b.dropna().mean())\n",
        "\n",
        "        rows[str(m)] = {\n",
        "            \"series\": series_name,\n",
        "            \"month\": m,\n",
        "            \"cut\": cut,\n",
        "            \"y_true\": y_true,\n",
        "            \"y_pred\": y_pred,\n",
        "        }\n",
        "\n",
        "    df = pd.DataFrame.from_dict(rows, orient=\"index\")\n",
        "    if not df.empty:\n",
        "        df = df.set_index(\"month\").sort_index()\n",
        "\n",
        "    if CFG.verbose and dropped:\n",
        "        miss = [str(m) for m in months if m not in df.index]\n",
        "        if miss:\n",
        "            print(f\"[{series_name}] Dropped months:\")\n",
        "            for mm in miss:\n",
        "                print(f\"  {mm}: {dropped.get(mm, 'unknown')}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Evaluation & DM-test\n",
        "# -----------------------------\n",
        "def _normal_cdf(z: float) -> float:\n",
        "    \"\"\"Standard normal CDF without SciPy.\"\"\"\n",
        "    return 0.5 * (1.0 + math.erf(z / math.sqrt(2.0)))\n",
        "\n",
        "\n",
        "def dm_test(y_true: pd.Series, y_model: pd.Series, y_rw: pd.Series, h: int = 1, loss: str = \"mse\"):\n",
        "    \"\"\"Diebold–Mariano test for equal predictive accuracy vs random walk benchmark.\"\"\"\n",
        "    df = pd.concat({\"y\": y_true, \"m\": y_model, \"rw\": y_rw}, axis=1).dropna()\n",
        "    if df.empty or len(df) < 5:\n",
        "        return float(\"nan\"), float(\"nan\")\n",
        "\n",
        "    e_m = df[\"y\"] - df[\"m\"]\n",
        "    e_r = df[\"y\"] - df[\"rw\"]\n",
        "    d = np.abs(e_m) - np.abs(e_r) if loss.lower() == \"mae\" else (e_m**2) - (e_r**2)\n",
        "\n",
        "    N = int(len(d))\n",
        "    d_mean = float(d.mean())\n",
        "    gamma0 = float(np.var(d, ddof=1)) if N > 1 else 0.0\n",
        "    var_bar = gamma0 / N\n",
        "\n",
        "    if h > 1 and N > 2:\n",
        "        for k in range(1, min(h - 1, N - 1) + 1):\n",
        "            w_k = 1.0 - k / h\n",
        "            cov_k = float(np.cov(d[k:], d[:-k], ddof=1)[0, 1])\n",
        "            var_bar += 2.0 * w_k * cov_k / N\n",
        "\n",
        "    if var_bar <= 0 or not np.isfinite(var_bar):\n",
        "        return float(\"nan\"), float(\"nan\")\n",
        "\n",
        "    dm_stat = d_mean / math.sqrt(var_bar)\n",
        "    p_val = 2.0 * (1.0 - _normal_cdf(abs(dm_stat)))\n",
        "    return dm_stat, p_val\n",
        "\n",
        "\n",
        "def evaluate_with_dm(eval_df: pd.DataFrame) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Compute RMSE, MAE, directional accuracy and DM-test vs random walk for one FX series.\n",
        "    \"\"\"\n",
        "    df = eval_df.copy()\n",
        "    df[\"err\"] = df[\"y_true\"] - df[\"y_pred\"]\n",
        "    core = df.dropna(subset=[\"y_true\", \"y_pred\"]).copy()\n",
        "\n",
        "    n_obs = int(len(core))\n",
        "    rmse = float(np.sqrt(np.mean(np.square(core[\"err\"])))) if n_obs else np.nan\n",
        "    mae  = float(mean_absolute_error(core[\"y_true\"], core[\"y_pred\"])) if n_obs else np.nan\n",
        "\n",
        "    core[\"y_prev\"] = core[\"y_true\"].shift(1)\n",
        "    mask = core[\"y_prev\"].notna()\n",
        "    dir_true = np.sign(core.loc[mask, \"y_true\"] - core.loc[mask, \"y_prev\"])\n",
        "    dir_pred = np.sign(core.loc[mask, \"y_pred\"] - core.loc[mask, \"y_prev\"])\n",
        "    hits = int((dir_true.values == dir_pred.values).sum())\n",
        "    total = int(mask.sum())\n",
        "    dir_acc = (hits / total) if total else np.nan\n",
        "\n",
        "    df[\"rw_pred\"] = df[\"y_true\"].shift(1)\n",
        "    dm_stat, p_val = dm_test(df[\"y_true\"], df[\"y_pred\"], df[\"rw_pred\"], h=1, loss=\"mse\")\n",
        "\n",
        "    return {\n",
        "        \"observations\": n_obs,\n",
        "        \"rmse\": rmse,\n",
        "        \"mae\": mae,\n",
        "        \"dir_hits\": hits,\n",
        "        \"dir_total\": total,\n",
        "        \"dir_acc\": dir_acc,\n",
        "        \"dm_stat\": float(dm_stat) if np.isfinite(dm_stat) else np.nan,\n",
        "        \"dm_pvalue\": float(p_val) if np.isfinite(p_val) else np.nan,\n",
        "    }\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Main\n",
        "# -----------------------------\n",
        "def main():\n",
        "    # 1) Load evaluation frame (multi-FX)\n",
        "    df_d = load_multi_fx(CFG.url_multi)\n",
        "\n",
        "    # Determine which numeric columns to run\n",
        "    all_cols = [c for c in df_d.columns if pd.api.types.is_numeric_dtype(df_d[c])]\n",
        "    if CFG.include_fx:\n",
        "        fx_cols = [c for c in CFG.include_fx if c in all_cols]\n",
        "    else:\n",
        "        fx_cols = all_cols\n",
        "\n",
        "    # 2) Load fine-tuning panel and fine-tune Chronos-2\n",
        "    fx_panel = load_finetune_fx_panel(CFG.url_finetune)\n",
        "    ft_start = fx_panel.index.min()\n",
        "    ft_end = fx_panel.index.max()\n",
        "\n",
        "    if CFG.verbose:\n",
        "        print(f\"\\nFine-tune panel: {ft_start.date()} → {ft_end.date()} | n={len(fx_panel)}\")\n",
        "        print(f\"Fine-tune FX columns: {FINETUNE_FX_COLS}\")\n",
        "\n",
        "    base_pipeline = build_base_chronos_pipeline()\n",
        "    ft_pipeline = finetune_chronos_on_nb_panel(base_pipeline, fx_panel)\n",
        "\n",
        "    # 3) Define evaluation start period as the first month AFTER fine-tune end month\n",
        "    #    Example: fine-tune ends 1999-12-31 → eval starts from 2000-01\n",
        "    eval_start_period = pd.Period(ft_end, freq=CFG.m_freq) + 1\n",
        "    if CFG.verbose:\n",
        "        print(f\"\\nEvaluation starts from period: {eval_start_period} (i.e., strictly after fine-tune period)\")\n",
        "\n",
        "    # 4) Build forecasting function based on fine-tuned pipeline\n",
        "    forecast_fn = build_model_chronos2_multi(\n",
        "        pipeline=ft_pipeline,\n",
        "        max_context=CFG.max_context,\n",
        "        horizon_len=CFG.max_horizon,\n",
        "    )\n",
        "\n",
        "    if CFG.verbose:\n",
        "        print(f\"\\nRunning monthly walk-forward for {len(fx_cols)} FX series:\", fx_cols)\n",
        "\n",
        "    # 5) Walk-forward and metrics per FX series (only months >= eval_start_period)\n",
        "    metrics_rows = []\n",
        "\n",
        "    for col in fx_cols:\n",
        "        S_b, S_d = series_daily_and_b(df_d, col)\n",
        "        if CFG.verbose:\n",
        "            print(f\"\\n[{col}] Data (B): {S_b.index.min().date()} → {S_b.index.max().date()} | n={len(S_b)}\")\n",
        "\n",
        "        df_eval = walk_forward_monthly(\n",
        "            S_b=S_b,\n",
        "            S_d=S_d,\n",
        "            forecast_fn=forecast_fn,\n",
        "            series_name=col,\n",
        "            start_period=eval_start_period,\n",
        "        )\n",
        "\n",
        "        if df_eval.empty or df_eval[\"y_pred\"].isna().all():\n",
        "            if CFG.verbose:\n",
        "                print(f\"[{col}] No evaluable months after fine-tune period; skipping.\")\n",
        "            continue\n",
        "\n",
        "        m = evaluate_with_dm(df_eval)\n",
        "        m[\"series\"] = col\n",
        "        metrics_rows.append(m)\n",
        "\n",
        "        if np.isfinite(m[\"dir_acc\"]) and m[\"dir_total\"] > 0:\n",
        "            print(\n",
        "                f\"[{col}] Obs={m['observations']}, RMSE={m['rmse']:.4f}, MAE={m['mae']:.4f}, \"\n",
        "                f\"DirAcc={m['dir_hits']}/{m['dir_total']} ({m['dir_acc']*100:.1f}%), \"\n",
        "                f\"DM={m['dm_stat']:.3f}, p={m['dm_pvalue']:.4f}\"\n",
        "            )\n",
        "        else:\n",
        "            print(\n",
        "                f\"[{col}] Obs={m['observations']}, RMSE={m['rmse']:.4f}, MAE={m['mae']:.4f}, \"\n",
        "                f\"DirAcc=NA, DM={m['dm_stat']:.3f}, p={m['dm_pvalue']:.4f}\"\n",
        "            )\n",
        "\n",
        "    # 6) Save metrics\n",
        "    if not metrics_rows:\n",
        "        print(\"No series produced metrics after the fine-tune period. Check data and settings.\")\n",
        "        return\n",
        "\n",
        "    metrics_df = pd.DataFrame(metrics_rows)[\n",
        "        [\"series\", \"observations\", \"rmse\", \"mae\", \"dir_hits\", \"dir_total\", \"dir_acc\", \"dm_stat\", \"dm_pvalue\"]\n",
        "    ].sort_values(\"rmse\")\n",
        "    metrics_df.to_csv(CFG.metrics_csv, index=False, encoding=\"utf-8-sig\")\n",
        "    print(f\"\\nSaved metrics to: {CFG.metrics_csv}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "C4Jc-C2tA-i7",
        "outputId": "15a6e352-0848-4720-a098-df96374e75e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fine-tune panel: 1980-12-10 → 1999-12-31 | n=4930\n",
            "Fine-tune FX columns: ['AUD', 'CAD', 'CHF', 'DKK', 'GBP', 'ISK', 'JPY', 'NZD', 'SEK', 'USD', 'XDR']\n",
            "\n",
            "[Fine-tuning Chronos-2 on Norges Bank FX panel 1980–1999]\n",
            "  Number of series: 11\n",
            "  Total length across series: 52815\n",
            "  prediction_length=32, num_steps=50, lr=1e-05, batch_size=2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2409010327.py:263: FutureWarning: Fine-tuning support is experimental and may be changed in future versions.\n",
            "  pipeline = pipeline.fit(\n",
            "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50/50 00:07, Epoch 1/9223372036854775807]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.024800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>2.704700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.760400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.748100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.498000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation starts from period: 2000-01 (i.e., strictly after fine-tune period)\n",
            "\n",
            "Running monthly walk-forward for 19 FX series: ['I44', 'AUD', 'EUR', 'CAD', 'GBP', 'HKD', 'JPY', 'MYR', 'NZD', 'SGD', 'SEK', 'PLN', 'USD', 'PHP', 'IDR', 'KRW', 'THB', 'TWD', 'XDR']\n",
            "\n",
            "[I44] Data (B): 1999-01-04 → 2024-12-12 | n=6769\n",
            "[I44] Obs=300, RMSE=1.4042, MAE=0.6603, DirAcc=190/299 (63.5%), DM=1.532, p=0.1255\n",
            "\n",
            "[AUD] Data (B): 1999-01-04 → 2024-12-12 | n=6769\n",
            "[AUD] Obs=300, RMSE=0.0979, MAE=0.0430, DirAcc=194/299 (64.9%), DM=1.259, p=0.2079\n",
            "\n",
            "[EUR] Data (B): 1999-01-04 → 2024-12-12 | n=6769\n",
            "[EUR] Obs=300, RMSE=0.1436, MAE=0.0636, DirAcc=198/299 (66.2%), DM=2.034, p=0.0420\n",
            "\n",
            "[CAD] Data (B): 1999-01-04 → 2024-12-12 | n=6769\n",
            "[CAD] Obs=300, RMSE=0.1044, MAE=0.0485, DirAcc=192/299 (64.2%), DM=1.231, p=0.2183\n",
            "\n",
            "[GBP] Data (B): 1999-01-04 → 2024-12-12 | n=6769\n",
            "[GBP] Obs=300, RMSE=0.2824, MAE=0.1150, DirAcc=170/299 (56.9%), DM=1.177, p=0.2393\n",
            "\n",
            "[HKD] Data (B): 1999-01-04 → 2024-12-12 | n=6769\n",
            "[HKD] Obs=300, RMSE=0.0265, MAE=0.0121, DirAcc=183/299 (61.2%), DM=1.821, p=0.0686\n",
            "\n",
            "[JPY] Data (B): 1999-01-04 → 2024-12-12 | n=6769\n",
            "[JPY] Obs=300, RMSE=0.2135, MAE=0.0907, DirAcc=183/299 (61.2%), DM=2.105, p=0.0353\n",
            "\n",
            "[MYR] Data (B): 1999-01-04 → 2024-12-12 | n=6769\n",
            "[MYR] Obs=300, RMSE=0.0414, MAE=0.0193, DirAcc=190/299 (63.5%), DM=1.823, p=0.0683\n",
            "\n",
            "[NZD] Data (B): 1999-01-04 → 2024-12-12 | n=6769\n",
            "[NZD] Obs=300, RMSE=0.0875, MAE=0.0420, DirAcc=197/299 (65.9%), DM=1.815, p=0.0696\n",
            "\n",
            "[SGD] Data (B): 1999-01-04 → 2024-12-12 | n=6769\n",
            "[SGD] Obs=300, RMSE=0.1107, MAE=0.0525, DirAcc=188/299 (62.9%), DM=0.524, p=0.5999\n",
            "\n",
            "[SEK] Data (B): 1999-01-04 → 2024-12-12 | n=6769\n",
            "[SEK] Obs=300, RMSE=1.4558, MAE=0.6654, DirAcc=199/299 (66.6%), DM=1.179, p=0.2383\n",
            "\n",
            "[PLN] Data (B): 1999-01-04 → 2024-12-12 | n=6769\n",
            "[PLN] Obs=300, RMSE=0.0496, MAE=0.0218, DirAcc=195/299 (65.2%), DM=1.540, p=0.1236\n",
            "\n",
            "[USD] Data (B): 1999-01-04 → 2024-12-12 | n=6769\n",
            "[USD] Obs=300, RMSE=0.2058, MAE=0.0938, DirAcc=185/299 (61.9%), DM=2.134, p=0.0329\n",
            "\n",
            "[PHP] Data (B): 1999-01-04 → 2024-12-12 | n=6769\n",
            "[PHP] Obs=300, RMSE=0.3907, MAE=0.2018, DirAcc=172/299 (57.5%), DM=1.931, p=0.0535\n",
            "\n",
            "[IDR] Data (B): 1999-01-04 → 2024-12-12 | n=6769\n",
            "[IDR] Obs=300, RMSE=0.0017, MAE=0.0008, DirAcc=181/299 (60.5%), DM=2.326, p=0.0200\n",
            "\n",
            "[KRW] Data (B): 1999-01-04 → 2024-12-12 | n=6769\n",
            "[KRW] Obs=300, RMSE=0.0158, MAE=0.0072, DirAcc=194/299 (64.9%), DM=0.814, p=0.4155\n",
            "\n",
            "[THB] Data (B): 1999-01-04 → 2024-12-12 | n=6769\n",
            "[THB] Obs=300, RMSE=0.5038, MAE=0.2385, DirAcc=176/299 (58.9%), DM=2.654, p=0.0080\n",
            "\n",
            "[TWD] Data (B): 1999-01-04 → 2024-12-12 | n=6769\n",
            "[TWD] Obs=300, RMSE=0.5666, MAE=0.2598, DirAcc=199/299 (66.6%), DM=1.992, p=0.0464\n",
            "\n",
            "[XDR] Data (B): 1999-01-04 → 2024-12-12 | n=6769\n",
            "[XDR] Obs=300, RMSE=0.2169, MAE=0.0948, DirAcc=195/299 (65.2%), DM=1.184, p=0.2365\n",
            "\n",
            "Saved metrics to: FX_Chronos2_finetuned_metrics_monthly_postFT.csv\n"
          ]
        }
      ]
    }
  ]
}